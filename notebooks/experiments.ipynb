{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!gdown https://drive.google.com/uc?id=1GweUxUAZJhhUVgKHnhL0Hwd6qGZ25BCe\n",
    "!gdown https://drive.google.com/uc?id=1HOSsnY0tUWlCjvIoxZPXkgx3J1tI_vgD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.read_csv(\"Kaggle_Training_Dataset_v2.csv\")\n",
    "test_data = pd.read_csv(\"Kaggle_Test_Dataset_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train_data.drop('went_on_backorder',axis=1)[:-1]\n",
    "Y_train = train_data['went_on_backorder'][:-1]\n",
    "X_test = test_data.drop('went_on_backorder',axis=1)[:-1]\n",
    "Y_test = test_data['went_on_backorder'][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns\n",
    "categorical_features = [ feature for feature in columns if X_train[feature].dtype == 'O' ]\n",
    "numeric_features = [ feature for feature in columns if feature not in categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.drop('sku',axis=1)\n",
    "X_test = X_test.drop('sku',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_train = Y_train.map({'Yes':1,'No':0})\n",
    "Y_test = Y_test.map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature == 'sku': continue\n",
    "    X_train[feature] = X_train[feature].map({'Yes':1,'No':0})\n",
    "    X_test[feature] = X_test[feature].map({'Yes':1,'No':0})\n",
    "#X_train[categorical_features] = X_train[categorical_features].apply(lambda x: x.map({'Yes':1,'No':0}),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train['perf_6_month_avg'].replace({-99:np.nan},inplace=True)\n",
    "X_train['perf_12_month_avg'].replace({-99:np.nan},inplace=True)\n",
    "X_test['perf_6_month_avg'].replace({-99:np.nan},inplace=True)\n",
    "X_test['perf_12_month_avg'].replace({-99:np.nan},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier,\n",
    "    #'CatBoost': CatBoostClassifier,\n",
    "    'LightGBM': LGBMClassifier,\n",
    "    'BalancedRandomForest': BalancedRandomForestClassifier,    \n",
    "    'SVC': SVC,\n",
    "    'RandomForest': RandomForestClassifier,\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optuna objective function\n",
    "def objective(trial, model_name, model_class):\n",
    "    # Define imputer selection\n",
    "    imputer_name = trial.suggest_categorical('imputer', ['SimpleImputer', 'IterativeImputer'])\n",
    "    if imputer_name == 'SimpleImputer':\n",
    "        imputer_strategy = trial.suggest_categorical('imputer__strategy', ['mean', 'median'])\n",
    "        imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "    elif imputer_name == 'IterativeImputer':\n",
    "        initial_strategy = trial.suggest_categorical('imputer__strategy', ['mean', 'median'])\n",
    "        imputer = IterativeImputer(initial_strategy=initial_strategy)\n",
    "\n",
    "    # Define hyperparameters to tune\n",
    "    if model_name == 'RandomForest' or model_name == 'BalancedRandomForest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 20, 70)\n",
    "        max_depth = trial.suggest_categorical('max_depth', [None, 10, 20, 30])\n",
    "        model = model_class(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    elif model_name == 'SVC':\n",
    "        C = trial.suggest_loguniform('C', 0.1, 10)\n",
    "        gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "        kernel = trial.suggest_categorical('kernel', ['rbf', 'linear'])\n",
    "        model = model_class(C=C, gamma=gamma, kernel=kernel)\n",
    "    elif model_name == 'XGBoost':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 20, 70 )\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.2)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 9)\n",
    "        model = model_class(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, eval_metric='mlogloss')\n",
    "    elif model_name == 'CatBoost':\n",
    "        iterations = trial.suggest_int('iterations', 100, 300)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.2)\n",
    "        depth = trial.suggest_int('depth', 3, 9)\n",
    "        model = model_class(iterations=iterations, learning_rate=learning_rate, depth=depth, verbose=0)\n",
    "    elif model_name == 'LightGBM':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 20, 70)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.2)\n",
    "        num_leaves = trial.suggest_int('num_leaves', 31, 60)\n",
    "        model = model_class(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves)\n",
    "\n",
    "    # Define preprocessing pipeline\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', imputer),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', SMOTE(random_state=42)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Cross-validation\n",
    "    score = cross_val_score(pipeline, X_train, Y_train, cv=3, scoring='roc_auc').mean()\n",
    "    return score\n",
    "\n",
    "# Store results\n",
    "best_estimators = {}\n",
    "best_params = {}\n",
    "best_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Optimize each model\n",
    "for model_name, model_class in models.items():\n",
    "    print(f\"Optimizing {model_name} with Optuna...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, model_name, model_class), n_trials=10,show_progress_bar=True,n_jobs=4)\n",
    "\n",
    "    best_estimators[model_name] = model_class(**{k.replace('model__', ''): v for k, v in study.best_params.items() if 'model__' in k})\n",
    "    best_params[model_name] = study.best_params\n",
    "    best_scores[model_name] = study.best_value\n",
    "    print(f\"Best Params for {model_name}: {study.best_params}\")\n",
    "    print(f\"Best CV Score for {model_name}: {study.best_value}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best models on test set\n",
    "for model_name in best_estimators.keys():\n",
    "    imputer_params = {k.replace('imputer__', ''): v for k, v in best_params[model_name].items() if 'imputer__' in k}\n",
    "    imputer_name = best_params[model_name]['imputer']\n",
    "    if imputer_name == 'SimpleImputer':\n",
    "        imputer = SimpleImputer(**imputer_params)\n",
    "    elif imputer_name == 'IterativeImputer':\n",
    "        imputer = IterativeImputer(**imputer_params)\n",
    "\n",
    "    # Define preprocessing pipeline\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', imputer),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, [0, 1, 2, 3])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create final pipeline\n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', SMOTE(random_state=42)),\n",
    "        ('model', best_estimators[model_name])\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy for {model_name}: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summary of results\n",
    "summary = pd.DataFrame({\n",
    "    'Model': list(best_scores.keys()),\n",
    "    'Best CV Score': list(best_scores.values()),\n",
    "    'Best Params': list(best_params.values())\n",
    "})\n",
    "\n",
    "print(\"\\nSummary of Optuna Results:\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
